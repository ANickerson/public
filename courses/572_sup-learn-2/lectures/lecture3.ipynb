{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 572 Lecture 3\n",
    "\n",
    "floating point numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.7755575615628914e-17"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# motivating example\n",
    "0.3 - 0.2 - 0.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(demonstrate this in other languages)\n",
    "\n",
    "Funny story: during my undergrad I send a bug report to MathWorks because I observed this behaviour in MATLAB. I got a very polite and patient response... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review from DSCI 521 of binary numbers and representations of integers (5-10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1011'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0:b}\".format(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this as $$1\\times 2^3 + 0\\times 2^2 + 1\\times 2^1 + 1\\times 2^0 = 8+2+1 = 11$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In practice there's one bit used as the \"sign bit\"\n",
    "- Since we don't need both positive 0 and negative 0, we keep one extra number on the negative side\n",
    "- So a 64-bit integer ranges from $-2^{63}$ to $2^{63}-1$, inclusive.\n",
    "- Python is special because it takes care of this for you behind the scenes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(2**100) # Python is special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] 1073741824\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R \n",
    "x = 1L\n",
    "for (i in 1:30) { # try 30 and 31\n",
    "  x = x * 2L\n",
    "}\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that R is using 32-bit integers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review scientific notation (0 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3423423974482344e+16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23423423974482344.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decimal numbers in binary (5 min)\n",
    "\n",
    "Consider the number $101.11$.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "$$1\\times 2^2 + 0\\times 2^1 + 1\\times 2^0 + 1\\times 2^{-1} + 1\\times 2^{-2} = 4+1+0.5+0.25 = 5.75$$\n",
    "\n",
    "Exercise: convert $1.10101$ to base 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain floating point system (20 min)\n",
    "\n",
    "Everything is represented in \"scientific notation\". In other words, $A \\times 10^B$. Except in this case it's more like $1.M \\times 2^E$, where $M$ is called the mantissa and $E$ is called the exponent.\n",
    "\n",
    "Examples:\n",
    "\n",
    "| number in base 10 | scientific notation | M (binary) | E (binary) | \n",
    "|--------------------|---------------------|-------------|--------|\n",
    "|  2                  |  $1\\times 2^1$    |  0           | 1      | \n",
    "| 0.375               |  $1.5\\times 2^{-2} $ |  1      |  -10  |\n",
    "| 0.1                 |  $1.?? \\times 2^{-4}$ | ?? | -100  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IEEE floating point standard**: https://en.wikipedia.org/wiki/IEEE_floating_point\n",
    "\n",
    "Key info: in IEEE double precision, we use 53 bits for the mantissa and 11 bits for the exponent (total = 64 bits).\n",
    "\n",
    "**Exercise** (5-10 min): calculate the smallest and largest possible floating point numbers.\n",
    "\n",
    "Then empirically check this. The largest one is about right. The smallest one is not right. This is because of sub-normal numbers (out of scope of lecture).\n",
    "\n",
    "NOTE: Python has a special behaviour that we need to watch out for. If you do something like `10**1000` you will get a giant integer. That's because Python has a dynamically expanding integer type. This has nothing to do with floating point representations, which are the thing we really care about for scientific computation (not to mention that most other languages, including R, do not do this). So, when playing around, make sure you write `10**1000.0` to ensure it's a floating point. Or `1e1000` but that doesn't work for other bases. \n",
    "\n",
    "(Also, and this is _REALLY_ out of scope but just FYI if anyone cares, in some languages `1eX` and `10^X` will return slightly different answers, if the language uses a special routine for `1eX` that is more optimized than the generral power function. I cannot imagine this ever mattering to any of us.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Result too large')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-963ef89ed3c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m: (34, 'Result too large')"
     ]
    }
   ],
   "source": [
    "2**1024.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.98846567431158e+307"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**1023.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two pieces of code that more-or-less do the same thing, namely convert a float to its binary representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from http://stackoverflow.com/questions/16444726/binary-representation-of-float-in-python-bits-not-hex\n",
    "\n",
    "import struct\n",
    "def binary(num):\n",
    "    # Struct can provide us with the float packed into bytes. The '!' ensures that\n",
    "    # it's in network byte order (big-endian) and the 'f' says that it should be\n",
    "    # packed as a float. Alternatively, for double-precision, you could use 'd'.\n",
    "    packed = struct.pack('!d', num)\n",
    "#     print('Packed: %s' % repr(packed))\n",
    "\n",
    "    # For each character in the returned string, we'll turn it into its corresponding\n",
    "    # integer code point\n",
    "    # \n",
    "    # [62, 163, 215, 10] = [ord(c) for c in '>\\xa3\\xd7\\n']\n",
    "#     integers = [ord(c) for c in packed]\n",
    "    integers = [c for c in packed]\n",
    "#     print('Integers: %s' % integers)\n",
    "\n",
    "    # For each integer, we'll convert it to its binary representation.\n",
    "    binaries = [bin(i) for i in integers]\n",
    "#     print('Binaries: %s' % binaries)\n",
    "\n",
    "    # Now strip off the '0b' from each of these\n",
    "    stripped_binaries = [s.replace('0b', '') for s in binaries]\n",
    "#     print('Stripped: %s' % stripped_binaries)\n",
    "\n",
    "    # Pad each byte's binary representation's with 0's to make sure it has all 8 bits:\n",
    "    #\n",
    "    # ['00111110', '10100011', '11010111', '00001010']\n",
    "    padded = [s.rjust(8, '0') for s in stripped_binaries]\n",
    "#     print('Padded: %s' % padded)\n",
    "\n",
    "    # At this point, we have each of the bytes for the network byte ordered float\n",
    "    # in an array as binary strings. Now we just concatenate them to get the total\n",
    "    # representation of the float:\n",
    "    final = ''.join(padded)\n",
    "    \n",
    "    print('Sign: %s' % final[0])\n",
    "    print('Exponent: %s' % final[1:12])\n",
    "    e1023 = \"{:011b}\".format(int(final[1:12],2)-1023)\n",
    "    print('Exponent - 1023: %s' % e1023)\n",
    "    print('Mantissa: %s' % final[12:])\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0100000000100000000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def float_to_bin(x): # does the same as the above, basically.\n",
    "    x = float(x)\n",
    "    if x == 0:\n",
    "        return \"0\" * 64\n",
    "    w, sign = (float.hex(x), 0) if x > 0 else (float.hex(x)[1:], 1)\n",
    "    mantissa, exp = int(w[4:17], 16), int(w[18:])\n",
    "    return \"{}{:011b}{:052b}\".format(sign, exp + 1023, mantissa)\n",
    "#     print('Sign: %s' % sign)\n",
    "#     print(\"Exponent: %s\" % exp)\n",
    "#     print(\"Mantissa: %s\" % mantissa)\n",
    "\n",
    "float_to_bin(8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sign: 0\n",
      "Exponent: 01111111011\n",
      "Exponent - 1023: -0000000100\n",
      "Mantissa: 1001100110011001100110011001100110011001100110011010\n"
     ]
    }
   ],
   "source": [
    "b = binary(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some take home messages (!!)\n",
    "\n",
    "- numbers are not represented exactly\n",
    "- most calculations are \"wrong\"\n",
    "- when these errors are introduced, **you might not get an error message or warning**\n",
    "- most numbers cannot be represented\n",
    "- even most _integers_ cannot be represented as floating point numbers\n",
    "- there is a biggest number\n",
    "- there is a smallest number\n",
    "- most environments you'll encounter will use IEEE double precision... but others do exist (especially single precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spacing between numbers\n",
    "\n",
    "Imagine you were in the decimal system (not binary), and were using scientific notation but you were only allowed 3 digits after the decimal point. In-class exercise: how large is the _spacing_ between the given number and the _next largest number that we can represent_?\n",
    "\n",
    "1. $1.259$\n",
    "2. $8.982$\n",
    "3. $3.432\\times 10^2$\n",
    "4. $0.001\\times 10^1$\n",
    "\n",
    "Conclusion: we only need to look at the exponent. \n",
    "\n",
    "The same goes for binary. The steps happen at every power of 2 instead of 10, and we have way more digits after the decimal (52 instead of 10), but everything else is pretty much the same.\n",
    "\n",
    "So the spacing size, as a function of the number itself, is a staircase function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x110ea1390>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npA77/xtYTpxTEegdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110cc4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.linspace(1,1000,1e5)\n",
    "spacing = 2**np.floor(np.log2(x))\n",
    "plt.plot(x, spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**-52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps get bigger, but the trend is a straight line. In other words, if we zoom out we see that the spacing size is _proportional to the number itself_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x104031588>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104031630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, spacing)\n",
    "plt.plot(x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look on a log-log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x112e2a208>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEHCAYAAACp9y31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFLxJREFUeJzt3X2MXNV5x/HfY1JHhTQlLP2jtrsOCSDeCnZNXf9RkaEm\nChI4lkKE7DhCm4wxIMVJyz9UahQPKrBxUlVuDAl0cSxeakxAbY3BJaRJxtSBErOUwBI7NiXF5iUY\nBISU0nq9e/rHrJ3rjWf3zsw55759P5K17J2Zew97ds48+9xznmPOOQEAqmNG1g0AAMTFwA8AFcPA\nDwAVw8APABXDwA8AFcPADwAVw8APABXDwA8AFfO+ECc1szMkfUlSn6QfOOduDXEdAEDnLOTKXTMz\nSXc4564IdhEAQEdSpXrMbIOZvWZmz0w6frGZ7TazPWZ23aTHlkh6UNI2f80FAPQqVcRvZn8q6b8l\n3emcO3fi2AxJeyQtlvSKpJ2Sljnndk967YPOuUt9NxwA0J1UOX7n3A4zmzvp8EJJe51zL0qSmW2W\ntFTSbjP7mKRPSXq/pIc8thcA0KNebu7OlrQ/8f1Lan0YyDm3XdL2qV5sZpQFBYAuOOesl9dnOp3T\nOZf5vzVr1uTifGlfl+Z50z2n3eOdHPf9c8tD/4XuOx/9181jee2/or33QvbfVMdHx0Z1w/YbdPLX\nTtbQ8JCXsbeXiP9lSf2J7+dMHCuUWq2Wi/OlfV2a5033nHaPd3o8D3y2LXTfpX3uVM/p5rG89l/R\n3ntpn+uzj+aeN1eLbl+kvuP7NLxqWP2/268rdeX0DZ1O2k86SR+W9Gzi++MkPS9prqSZkp6WdGYH\n53MorjVr1mTdBPSA/su30bFRd8P2G9zJXzvZDQ0PufHx8SOPTYydPf11lCriN7NNkmqS+sxsn6Q1\nzrmNZrZa0iNqpYw2OOd2dfKh02g0VKvVchuRoD36rNjov/waOTCigX8eOCrKl6Rms6lms+nlGkEX\ncE15YTOX1bUBIG8OjR/S2h1rte6JdRpcPKj6/Lpaa2CPZmZyPd7cDVKyAQCQXrsoP5RMZ/U0Gg1v\nf7oAQNEcGj+kGx+9URfecaGuPv9qPbzi4baDfrPZVKPR8HJdUj0AkIFklD+0ZCh1lO8j1UNZZgCI\nqJMoPxRy/AAQSexcfjtE/AAQWB6i/KRMI37m8QMoO19RPvP4ASDn0s7L7xTz+AEgh/KSy2+HHD8A\neJK3XH47RPwA4EHeo/wkVu4CQA9iRfms3AWAHOh29W0vWLkLABkoSi6/HXL8ANCBIuXy22HgB4AU\nDo0f0qo71+qeF9Zp4a8G9eH36rppR+/z8rPAwA8A0zgc5b++r09/9sKwllxQvCg/iZINANDG5NW3\nPxmp67RFpquvjt8WSjYAQGDHmrGzerV0+unS6tXZtYtZPQDg2VQzdpyTPJTbyRw5fgCYMN2MnfHx\ncgz8RPwAKi/tvHznpBklGDWJ+AFUWifz8suS6inBZxcAdK6b1bdlSfUwnRNA5XS7+jbLiJ/pnADQ\nhV53xVq5Ulq0qPU1K+zABQAp+aixQ44fAArAZyVNcvwAkHO+K2mWZTpnCf4XAOBooerllyXVQ8QP\noFRC1ssvS6qHiB9AKcTYFYuIHwByItauWOT4PWg0Gt4WJAConth732a9gKvRaHg5Fwu4ABTSserl\nh7ZsmbR0qbR8efBLtUU9fgCVEzvKTypLqoccP4DCiJXLb4ebuwAQyejYIV37j2t19/Pr9IUzBrX0\nD+p6/XnT65Hb8eabDPwAENzIgREtv3dAzz3Zp7P/c1jb7u/XtozaYiZ95CMZXdwjBn4AuZSspPnF\nswb1D9+s69ldJQi3c4CBH0DuTM7l/+qlft3DmO9NCe5PAyiLdjN2yjKbJi+I+AHkwlQzdsoymyYv\n+AwFkKk08/LLUhwtL4j4AWQm7bx8In6/iPgBRNfp6lty/H5lGvE3Gg3VajXVarUsmwEgom5W3xLx\nt4q0+SpqSZE2AFEk5+UPLh5UfX5dlnI0f/JJ6aqrpOHhwI0sAB9F2sjxAwiu1xo7pHr84kcJIBhf\nlTRJ9fhFxA8gCJ+VNBn4/SLiB+BViHr5zOP3i4gfgDeh6uWT4/eLHyWAnoXeFYtUj19E/AB6EmNX\nLFI9fhHxA+hKzL1vifj9IuIH0LHYe9+S4/eLHyWA1GJG+UlE/H4R8QNIJXaUn0SO3y8ifgBTyirK\nTyLV4xdF2gC0NXJgRB+/ZUDvvtGnuT8Z0sz34g74h73zjvTRj0oPP5zJ5XOFIm0AgkhW0vzQzwbV\nuLCu8z+fba5l9uxML18qDPwAjjI5l7/i0n6deaa0YEHWLYMvwbJmZrbUzP7ezO4xs4+Hug4AP9rl\n8plRUz7BIn7n3BZJW8zsRElfl/S9UNcC0JupZuyMj3NjtWxSd6eZbTCz18zsmUnHLzaz3Wa2x8yu\nO8ZLvyzpll4bCsC/NDN2iPjLp5OIf6Ok9ZLuPHzAzGZIulnSYkmvSNppZlucc7snHv+qpG3Ouaf9\nNRmAD2nn5TPwl0/qiN85t0PSW5MOL5S01zn3onNuVNJmSUslycxWq/WB8GkzW+WpvQB61Om8fFI9\n5dNrjn+2pP2J719S68NAzrn1av2FACAnull9S8RfPplO52w0Gkf+u1arqVarZdYWoMyS8/IHFw+q\nPr8uSzmaM/Bnq9lsqtlsej1nRyt3zWyupK3OuXMnvl8kqeGcu3ji+7+U5Jxza1Oci5W7QATJKH9o\nyVDH5RYWLJBuu006//xADURHfKzc7TRzZxP/Dtsp6VQzm2tmMyUtk/RALw0C4IevGjvk+MsndarH\nzDZJqknqM7N9ktY45zZO3MR9RK0PkQ3OuV1pz9loNEjxAAH4rKRJqicffKZ8KNIGlEgvufx2zjtP\nuuMOad48T41ETyjSBuCIUPXySfWUD90JFFzoevmkeson8+mc5PiB7sXYFYuBPx/I8QMVFyKX385Z\nZ0n339/6iuyR4wcqKPbet+x3Wz7k+IGCyGrvW1I95UOOHyiA2FF+Ehud5wM5fqAiYuby2zntNGnb\nttZXZI8cP1BiO/aMaMV9AzphRp/+4oPDOvTjft324/jtePttUj1lw8AP5MzhKH/to+v0/n8b1MWn\n1LVPpn0ZtWf5cmnWrIwujiAY+IEcSeby/3rOsP79pH7ddmvWrULZZHrLptFoeK8zDRTRsWbs9L2v\nn5uqOKLZbB61h0kvuLkLZKxdvfy77pK++13p7rszbiByJYt6/AA8mW5ePvPnEQo5fiADaeblUxUT\nofBrBUTUyepbIn6EQsQPRNLp6lsGfoTCrB4gsG5r7JDqQRKzeoCCaDdjJ42hIemJJ6Tbbw/YQBQO\ns3qAnPJRSZNUD0Ihxw945quSJlUxEQq/VoAnvuvlswEKQiHiBzwIUS+fVA9CIeIHehByVyxSPQiF\nHbiALoXeFYtUD5LYgQvIUKxdsb7xDWnvXmn9eu+nRoGxAxcQWcy9b0n1IBR+rYAUQuby2+HmLkIh\n4gemETPKTyLHj1CI+IE2sojyk0j1IBQifuAYnn1tRJ/bMqCTfrtPO1e2onznWoNxLET8CIWBH0g4\nPGPnK/+yTuOPDEr/UddHlN3oe9NNmV0aJcbAD0xI5vJPuHtY+57t14knZt0qwD8yiKi8Y+Xy9ct+\n0iwoLVbuotLazdjhxiryhpW7QI+mW337gQ9Iv/hF6yuQJ6zcBbqQZl4+M2pQZvwxi8roZF4+qR6U\nGRE/KqHT1beUS0CZEdOg1LpdfUuqB2VGxI/S6qXGDqkelBm/2igdHzV2iPhRZkT8KBVflTSJ+FFm\n/GqjFHxX0uTmLsqMiB+F57te/uF1hQz8KCsifhRWqHr5RPsoOyJ+FFLIXbEY+FF2mUb8jUbDW9Eh\nVEOMXbGY0YM8ajabajQaXs5FkTYURjLKH1oyFGwbxIMHW8XZDh4McnqgJz6KtJHjR+7F3vuWVA/K\njhw/ci1kLr+d8XHm8KPc+PVGLsWO8pOI+FF2RPzInSyi/CRu7qLsGPiRG4fGD+mqO9dq0wvrtODt\nQc1+t67rfxh/BB4dJdWDcmPgRy4cjvLf2N+nC58f1mUXxY3yJ7v88kwvDwTFwI9MTd779qc/q2vW\nAlO9nnXLgPJi4EdmjpXLv/Zu8utAaGQyEd1UM3aYSgmER8SPqKabscNUSiA8YitEkXZePlMpgfCI\n+BFcJ/Py2fkKCI+3GILpZvUtqR4gPCJ+BNHt6ltu7gLhBXmLmdkpZna7mX0nxPmRX73W2CHiB8IL\nEvE7534uaSUDf7X4qLFDjh8IL9VbzMw2mNlrZvbMpOMXm9luM9tjZteFaSLyzmclTWb1AOGljfg3\nSlov6c7DB8xshqSbJS2W9IqknWa2xTm3O/E63sIl57uSJqkeILxUEb9zboektyYdXihpr3PuRefc\nqKTNkpZKkpmdZGbfkjSPvwTKKVS9fFI9QHi95PhnS9qf+P4ltT4M5Jx7U9I1PZwbORayXj6pHiC8\nTKdzJneMr9VqqtVqmbUF05tcSbM+vy7zPEoT8QNHazabajabXs/Zy8D/sqRkqDdn4lhqyYEf+RZr\nVywifuBok4Pi66+/vudzdhJbmY6+WbtT0qlmNtfMZkpaJumBnluEXIm99y03d4HwUkX8ZrZJUk1S\nn5ntk7TGObfRzFZLekStD5ANzrldnVy80WiQ4smxLPa+JdUDHJvPlI8557ycqOMLm7msro2pxcjl\nt/OZz0iXXCKtWBHlckDhmJmccz29IanVg6NkEeUnEfED4THwQ5I0OnZIf37fWm16YZ2uOX1Qn5xT\n16u7Ta9Gbscbb5DjB0LLfDonOf7sjRwY0bJ7B7TryT794X8N6/tb+vX9jNpiJp16akYXB3KMHD+8\nSObyv3DmoO69rq6fPke4DeQZOX50bXIu/5f7+nU/uXWgEnirV0y7efnMnweqg4i/QqaascOKWaA6\nMo34G42G9xoU+E1pVt8yjRLIt2az6a3MDTd3Sy4Z5Q8tGWo7L/+pp6SVK1tfAeSXj5u7xHgl1WmN\nHVI9QHWQ4y+hblbfkuoBqoO3eon0UkmTWT1AdbBytyR6rbFDqgfIN1bu4ghflTQff1y69trWVwD5\nxcrdivNZSZOIH6gOcvwFFGJXLG7uAtVBxF8woerlc3MXqA5W7hZE6L1vSfUA+cbK3YpJu/q2F82m\n1Gi0vgLIL1bullzoKD+JVA9QHeT4cyr23rekeoDqIOLPmZhRfhKzeoDqIOLPkdhRfhIRP1AdxHg5\nkFWUn0TED1QHs3oyNnJgRBfdPKB33+jTnKeGNPO9uAP+Ye+8I51zjrR1ayaXB5BS4Us2VLlIW7LG\nzof2DOqGi+r646uyzbXMmpXp5QFMgSJtBTd5Xv6KS/t1443SBRdk3TIAecc8/oJpl8vnxiqAmJjV\nE8lUM3a4sQogJoabwNLM2GHVLICYiPgDSjsvf3yciB9APAw3AXQ6L5+IH0BMRPyedbP6logfQEwM\nN570svqWiB9ATCzg8qDXGjsM/ACmwwKunEiuvh1cPKj6/LqsixF83jxp40Zp/vwAjQRQKoUv2VBk\nPitpEvEDiIkcf4dCVNJkAReAmIj4OxCqXj4lGwDERJyZQuh6+aR6AMRExD+NGLtikeoBEBPDTRsx\nd8Ui1QMgJiL+Y4i99y0RP4CYGG4Sstr7logfQExE/BNiR/lJRPwAYqr8cJNVlJ/ErB4AMVU64n9y\n34guu2tAx1ufVp8wrP99rF+3PBa/HW+/zcAPIJ5KFmk7XGPnb3as09i/DurSs+s6INOBqK34tYEB\nadasjC4OoBAo0taDZC5/1e8P6W+/0q8f/Sh6MwCgKz6KtFUmx3+sXP7v/VY/N1UBVE4lcvztZuyM\nj0vHHZdx4wAgslLHu9PN2BkbY+AHUD2ljfjTzMtn4AdQRaWL+DuZlz82xsIpANVTqoi/09W3RPwA\nqqgU8W63q2+5uQugigof8fdSY4eIH0AVFTbi91Fjhxw/gCoqZMTvq5ImET+AKipUvOu7kiY5fgBV\nVJiIP0S9fCJ+AFWU+4g/ZL18cvwAqijXEX/oXbGI+AFUUS7j3Vi7YjHwA6iiIBG/mR0v6ZuS/k/S\ndufcprSvjbn3LTd3AVRRqIj/U5Luc85dJemTaV6Qxd635Pi752snIGSD/qu2VMOemW0ws9fM7JlJ\nxy82s91mtsfMrks8NEfS/on/Hpvu/CMHRrTo9kV6dN+jGl41rJV/tFIWYRNaUj3dY+AoNvqv2tLG\nuxslfSJ5wMxmSLp54vjZkpab2RkTD+9Xa/CXpLYjeBZRftLYmPTqq02v5+z2DZX2dWmeN91z2j3e\n6fE88Nm20H2X9rlTPaebx/Laf77bVeT+i913qQZ+59wOSW9NOrxQ0l7n3IvOuVFJmyUtnXjsnyR9\n2sxukbS13Xn/ZGiRfvjz7Xp8YFhXnLNSo6OmgwcV9d8rrzQ7/ZlNiYE/Lgb+6R/La/8x8Hd/vFep\nN1s3s7mStjrnzp34/jJJn3DOrZr4/rOSFjrnvpjyfNns8g4ABdfrZuuZzePvteEAgO70MqflZUnJ\nhPyciWMAgBzrZOA3HX2jdqekU81srpnNlLRM0gM+GwcA8C/tdM5Nkh6TdLqZ7TOzzznnxiStlvSI\npOckbXbO7QrXVACAD6lv7gIAyiFXRdp6KfWA7JnZKZL+StIHnXOXZ90epGdmSyVdIul3JH3bOfe9\njJuEDkysofqSpD5JP3DO3Trl8/MU8U9MCX3LOfeQmW12zi3Luk3onJl9h4G/mMzsRElfd85dmXVb\n0DlrlTy4wzl3xVTPC1qpJnSpB4TVRf8hJ3rouy9LuiVOK9FON/1nZkskPShp23TnD12iLEipB0TT\naf8deVqc5mEKHfedmX1V0jbn3NMxG4pj6rj/nHNbnXOXSPrsdCcPOvCHKvWAODrtPzM7ycy+JWke\nfwlkq4u+Wy1psVrvv1VRG4vf0EX/fczM/s7MbpX00HTnz+Lm7mz9Op0jSS+p9T8k59z/SPp8Bm1C\nelP135uSrsmiUUhlqr5bL2l9Fo1CalP133ZJ29OeiGr0AFAxWQz8lHooNvqvuOi7YvPWfzEGfko9\nFBv9V1z0XbEF67/Q0zkp9VBg9F9x0XfFFrr/crWACwAQHjd3AaBiGPgBoGIY+AGgYhj4AaBiGPgB\noGIY+AGgYhj4AaBiGPgBoGIY+AGgYv4fU5FtF3cjzTAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110edd630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(x,spacing)\n",
    "plt.loglog(x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### order of operations\n",
    "\n",
    "Consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e16 + 1 + 1 == 1e16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e16 + 2 == 1e16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e40 + 10000000 == 1e40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1e-20 == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now understand the above, given our new knowledge. The spacing between $10^{16}$ and the next largest number must be more than 2, so when 1 is added to $10^{16}$ we round back down to $10^{16}$. But consider the below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 1 + 1e16 == 1e16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What?? But we just said...  but ...\n",
    "\n",
    "This is surprising because we changed the order and got different results. To put it more clearly,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e16+1+1 == 1+1+1e16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here is that we do operations from left to right. So when we first do 1+1 we get 2. And I picked $10^{16}$ on purpose so that the spacing is more than 2 but less than 4. So when we add 2 to $10^{16}$ we do get far enough to round _up_ to the next number. In other words, the order of operations doesn't matter on paper, but it can matter in code due to floating point issues. \n",
    "\n",
    "\n",
    "(begin bonus) By the way, what _is_ the spacing at $10^{16}$? We need to find the larest power of 2 that is less than $10^{16}$, which happens to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9007199254740992.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.0**53 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.0072e+15'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make it easier to read\n",
    "'%g' % 2.0**53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok this looks good. So now we just need to do $2^{53}\\times 2^{-52}=2$. So the spacing is exactly 2. I guess we round up! (end bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### log-sum-exp\n",
    "\n",
    "In the lab you are asked to implement logistic regression. Here we'll consider the binary classification case. To make things cleaner let's also assume $d=1$. \n",
    "\n",
    "The loss function is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss_lr_1D(w, x, y):\n",
    "    return np.sum(np.log(1 + np.exp(-y*w*x)))\n",
    "\n",
    "\n",
    "N = 100\n",
    "x = np.random.randn(N)\n",
    "x[1:10] *= 1e5\n",
    "w = np.random.randn()\n",
    "y = np.random.choice([-1,+1], size=N)\n",
    "\n",
    "loss_lr_1D(w,x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are doing here?\n",
    "\n",
    "$$\\mathcal{L}(w) =  \\sum_{n=1}^N \\log \\left( 1+ \\exp(-y_nwx_n) \\right) $$\n",
    "\n",
    "The key is that we're computing $\\log(1+\\exp(z))$ and getting an overflow when $z\\gg 1$. \n",
    "\n",
    "(Note: when doing the optimization, we only really need the gradient of the loss, so this isn't a completely realistic concern. But it happens for real for multi-class.)\n",
    "\n",
    "But when $z\\gg1$ we can say $1+\\exp(z)\\approx \\exp(z)$ and in that case  \n",
    "\n",
    "$$\\log(1+\\exp(z))\\approx \\log(\\exp(z)) = z$$\n",
    "\n",
    "We can try it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n",
      "0.69314718056\n",
      "110.0\n",
      "110\n",
      "inf\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def log_1_plus_exp(z):\n",
    "    return np.log(1+np.exp(z))\n",
    "\n",
    "def log_1_plus_exp_safe(z):\n",
    "    if z > 100:\n",
    "        return z\n",
    "    else:\n",
    "        return np.log(1+np.exp(z))\n",
    "\n",
    "\n",
    "print(log_1_plus_exp(0))\n",
    "print(log_1_plus_exp_safe(0))\n",
    "\n",
    "print(log_1_plus_exp(110))\n",
    "print(log_1_plus_exp_safe(110))\n",
    "\n",
    "print(log_1_plus_exp(1000))\n",
    "print(log_1_plus_exp_safe(1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional) What about underflow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(log_1_plus_exp(-100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? Because"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7200759760208361e-44"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is not zero. Hmm. But..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+np.exp(-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+np.exp(-100)==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! The above equals 1. So that's the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, when $z\\ll -1$ then $\\exp(z)$ is very small. Let's call it $\\epsilon$. So we have \n",
    "\n",
    "$$\\log(1+\\epsilon)\\approx \\epsilon$$ for $\\epsilon$ very small (this comes from the Taylor expansion). \n",
    "\n",
    "So now we can say\n",
    "\n",
    "$$\\log(1+\\exp(z))\\approx\\exp(z)$$ when $$z\\ll -1$$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n",
      "0.69314718056\n",
      "110.0\n",
      "110\n",
      "inf\n",
      "1000\n",
      "4.53988992169e-05\n",
      "4.53988992169e-05\n",
      "0.0\n",
      "1.68891188022e-48\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgelbart/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def log_1_plus_exp_safer(z):\n",
    "    if z > 100:\n",
    "        return z\n",
    "    elif z < -100:\n",
    "        return np.exp(z)\n",
    "    else:\n",
    "        return np.log(1+np.exp(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n",
      "0.69314718056\n"
     ]
    }
   ],
   "source": [
    "# both ok\n",
    "print(log_1_plus_exp(0))\n",
    "print(log_1_plus_exp_safer(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.0\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "# both OK (but approximation is invoked)\n",
    "print(log_1_plus_exp(110))\n",
    "print(log_1_plus_exp_safer(110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgelbart/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# only safer version works\n",
    "print(log_1_plus_exp(1000))\n",
    "print(log_1_plus_exp_safer(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.53988992169e-05\n",
      "4.53988992169e-05\n"
     ]
    }
   ],
   "source": [
    "# both OK\n",
    "print(log_1_plus_exp(-10))\n",
    "print(log_1_plus_exp_safer(-10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.68891188022e-48\n"
     ]
    }
   ],
   "source": [
    "# only safer version works\n",
    "print(log_1_plus_exp(-110))\n",
    "print(log_1_plus_exp_safer(-110))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# both fail\n",
    "print(log_1_plus_exp(-1000))\n",
    "print(log_1_plus_exp_safer(-1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### more take-home messages\n",
    "\n",
    "- by combining an understanding of floating point errors and math, we can write better code\n",
    "- this is one (of many) reasons why we use libraries like sklearn rather than implementing things ourself. other reasons: speed, edge cases, updates over time, less likely to contain a bug.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a careful analysis of floating point numbers you can also reason about what the conditions should be. I just picked -100 and 100 arbitrarily. It turns out my choice was imperfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(log_1_plus_exp_safer(-99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out +100 and -30 are a pretty good choices. These require careful reasoning (beyond the scope here, ask if you're interested)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### moving to $d>1$ and multi-class\n",
    "\n",
    "When $d>1$ not much changes, except that your $z$ above is actually a dot product of a $w$-vector and an $x$-vector, so getting big numbers in there starts to be a much bigger problem. The above is then even more important. \n",
    "\n",
    "Imagine $d=1000000$. Even if these numbers look like random noise (both positive and negative, cancelling each other out) by the central limit theorem their sum will grow like $\\sqrt{N}$ and eventually overflow will be a problem. You only need to get to $z=1000$ before problems hit.\n",
    "\n",
    "When the number of classes change then things change more substantially. In particular with $K$ classes the $\\log(1+\\exp(z))$ flavour changes to\n",
    "\n",
    "$$\\log\\left(\\sum_{k=1}^K \\exp(z_k)\\right)$$\n",
    "\n",
    "In that case we play a different trick which is to pull out the max $z_k$. More info [here](https://hips.seas.harvard.edu/blog/2013/01/09/computing-log-sum-exp/) and an optional question in lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### inverting matrices\n",
    "\n",
    "Sometime we take the inverse of a matrix. For example:\n",
    "\n",
    "- [DSCI 561 lecture 7](https://github.ubc.ca/ubc-mds-2016/DSCI_561_regr-1_students/blob/master/lectures/lect07_diagnostics.pdf), slide 6\n",
    "- [DSCI 553 lecture 6](https://github.ubc.ca/ubc-mds-2016/DSCI_553_stat-inf-2_students/blob/master/Lecture6scrb.pdf),  slide 5\n",
    "\n",
    "Key point: _this is almost always a bad idea!_\n",
    "\n",
    "- If you actually need the inverse, then you must compute it\n",
    "- But in real situations you almost always need to solve $Ax=b$ given some $b$\n",
    "- In this case, use a solve function to compute this directly, rather than going to $x=A^{-1}b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "\n",
    "A = np.random.rand(3,3) # random 3x3 matrix\n",
    "b = np.random.rand(3)\n",
    "\n",
    "x1 = npla.inv(A) @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x2 = npla.solve(A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(x1,x2) # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 250\n",
    "A = np.vander(np.random.rand(n))\n",
    "b = np.random.rand(n)\n",
    "\n",
    "y1 = npla.inv(A) @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2 = npla.solve(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(y1,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.6760089777294697e+96"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(y1-y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened??\n",
    "\n",
    "Well, we're not really going to go into this. There are courses on this like CPSC 302 and 402. But, basically, just don't compute the inverse if you don't have to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
